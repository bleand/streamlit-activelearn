{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b6707ad",
   "metadata": {},
   "source": [
    "## Simple Active Learn\n",
    "\n",
    "This notebook shows a very simple implementation of active learn.\n",
    "\n",
    "Active learn is a technique that can enable data scientist to generate a labeled dataset from an unlabeled one easier than labeling it completely.\n",
    "There is labeling involved, but this process uses a model to identify the best samples to annotate reducing the time that it takes and providing immediate feedback on when the dataset is good enough.\n",
    "\n",
    "Active Learn can be splitted into 3 steps.\n",
    "* 1: Seeding\n",
    "* 2: Similarity\n",
    "* 3: Iteration\n",
    "\n",
    "On 1, we provide seeds (i.e. samples of each class) to identify potentially easy datapoints.\n",
    "Then, we do a similarity search on the dataset and present other similar samples that could be also used as starting points.\n",
    "Finally, we iterate by training a model with the current dataset, making predictions in the unlabeled dataset, and the best samples to annotate next. This last step can be repeated until we are pleased with the metrics.\n",
    "\n",
    "It is important to note, that though the first two steps are not strictly necessary and one can jump right to the iteration, providing seeds helps the model to find the right samples sooner and could save precious time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7798af6f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75781b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy\n",
    "import numpy as np\n",
    "from ipyannotations.generic import ClassLabeller\n",
    "from modAL.models import ActiveLearner\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cad94f",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "\n",
    "For this experiment, are going to use the IMDB reviews sentiment dataset, and though we have the actual label, only the review column will be used. \n",
    "\n",
    "We'll generate the labels using Active Learn\n",
    "\n",
    "The reason for keeping a dataset with labels in here, is so we can later compare a model generated through active learn vs a model generated with all the labels from the beginning.\n",
    "\n",
    "For this, we are doing an 80-20 split of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4225c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./../data/IMDB Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c124ed8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecb5334",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['len'] = dataset.apply(lambda x: len(x.review.split(\" \")), axis=1)\n",
    "dataset = dataset[dataset[\"len\"] < 300]\n",
    "# dataset['len'] = dataset.apply(lambda x: len(x.review), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d82e9b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38778.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>157.007582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.085023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                len\n",
       "count  38778.000000\n",
       "mean     157.007582\n",
       "std       61.085023\n",
       "min        4.000000\n",
       "25%      118.000000\n",
       "50%      148.000000\n",
       "75%      197.000000\n",
       "max      299.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "709f9171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset[\"len\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31e5d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775cc8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_dataset = train_dataset[['review']]\n",
    "al_dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85f51313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34568</th>\n",
       "      <td>with a title like this, you know not to expect...</td>\n",
       "      <td>negative</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17938</th>\n",
       "      <td>So what's the big fuss out of making an INDIAN...</td>\n",
       "      <td>negative</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15827</th>\n",
       "      <td>Horrendous pillaging of a classic.&lt;br /&gt;&lt;br /&gt;...</td>\n",
       "      <td>negative</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>I don't normally write reviews, but this \"film...</td>\n",
       "      <td>negative</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28581</th>\n",
       "      <td>Think Jumanji but with a death curse. A bunch ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment  len\n",
       "34568  with a title like this, you know not to expect...  negative  170\n",
       "17938  So what's the big fuss out of making an INDIAN...  negative  122\n",
       "15827  Horrendous pillaging of a classic.<br /><br />...  negative  190\n",
       "565    I don't normally write reviews, but this \"film...  negative  232\n",
       "28581  Think Jumanji but with a death curse. A bunch ...  negative  120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1699d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with a title like this, you know not to expect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So what's the big fuss out of making an INDIAN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Horrendous pillaging of a classic.&lt;br /&gt;&lt;br /&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't normally write reviews, but this \"film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Think Jumanji but with a death curse. A bunch ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review\n",
       "0  with a title like this, you know not to expect...\n",
       "1  So what's the big fuss out of making an INDIAN...\n",
       "2  Horrendous pillaging of a classic.<br /><br />...\n",
       "3  I don't normally write reviews, but this \"film...\n",
       "4  Think Jumanji but with a death curse. A bunch ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "al_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e786c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = test_dataset.rename(columns={'sentiment':'label'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7643de1",
   "metadata": {},
   "source": [
    "### Seeds\n",
    "\n",
    "What is very insteresting about seeds, is that they don't really need to be part of the dataset. Though in many scenarios it'd be easier to just go to the dataset and pick a few examples, here we already know what good and bad reviews are, so we can just come up with a few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3972451",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_reviews_seeds = [\n",
    "    \"\"\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\"\",\n",
    "    \"\"\"A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master's of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional 'dream' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell's murals decorating every surface) are terribly well done.\"\"\",\n",
    "    \"\"\"I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I'd laughed at one of Woody's comedies in years (dare I say a decade?). While I've never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f3d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_reviews_seeds = [\n",
    "    \"\"\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\"\"\",\n",
    "    \"\"\"This show was an amazing, fresh & innovative idea in the 70's when it first aired. The first 7 or 8 years were brilliant, but things dropped off after that. By 1990, the show was not really funny anymore, and it's continued its decline further to the complete waste of time it is today.<br /><br />It's truly disgraceful how far this show has fallen. The writing is painfully bad, the performances are almost as bad - if not for the mildly entertaining respite of the guest-hosts, this show probably wouldn't still be on the air. I find it so hard to believe that the same creator that hand-selected the original cast also chose the band of hacks that followed. How can one recognize such brilliance and then see fit to replace it with such mediocrity? I felt I must give 2 stars out of respect for the original cast that made this show such a huge success. As it is now, the show is just awful. I can't believe it's still on the air.\"\"\",\n",
    "    \"\"\"I saw this movie when I was about 12 when it came out. I recall the scariest scene was the big bird eating men dangling helplessly from parachutes right out of the air. The horror. The horror.<br /><br />As a young kid going to these cheesy B films on Saturday afternoons, I still was tired of the formula for these monster type movies that usually included the hero, a beautiful woman who might be the daughter of a professor and a happy resolution when the monster died in the end. I didn't care much for the romantic angle as a 12 year old and the predictable plots. I love them now for the unintentional humor.<br /><br />But, about a year or so later, I saw Psycho when it came out and I loved that the star, Janet Leigh, was bumped off early in the film. I sat up and took notice at that point. Since screenwriters are making up the story, make it up to be as scary as possible and not from a well-worn formula. There are no rules.\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4784f0",
   "metadata": {},
   "source": [
    "### Similarity\n",
    "\n",
    "Once we have the seeds, now we can find similar samples in our corpus to start the labelling process.\n",
    "\n",
    "Based on the problem, this is a point where we can get very creative or keep it simple. We are going for the second option here.\n",
    "\n",
    "For each seed, we'll get two similar reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ba2753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=10000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorizer = HashingVectorizer(n_features=600,ngram_range=(1,6),lowercase=False,analyzer='char_wb')\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "vectorizer.fit(al_dataset.review.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec283d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# good_vectors = vectorizer.fit_transform(good_reviews_seeds).todense()\n",
    "good_vectors = vectorizer.transform(good_reviews_seeds).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c787931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_vectors = vectorizer.fit_transform(bad_reviews_seeds).todense()\n",
    "bad_vectors = vectorizer.transform(bad_reviews_seeds).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7833771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_vectors = vectorizer.fit_transform(al_dataset.review.tolist()).todense()\n",
    "reviews_vectors = vectorizer.transform(al_dataset.review.tolist()).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62f08361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ccdc116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31022, 10000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b984223e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 2\n",
    "\n",
    "# Calculate cosine distance (opposite to cosine similarity)\n",
    "good_distances = scipy.spatial.distance.cdist(good_vectors, reviews_vectors, metric='cosine')\n",
    "bad_distances = scipy.spatial.distance.cdist(bad_vectors, reviews_vectors, metric='cosine')\n",
    "\n",
    "# Sort in ascending order and pick the first 10 of each\n",
    "closest_k_good = np.argsort(good_distances)[:, :NUM_SAMPLES].flatten()\n",
    "closest_k_bad = np.argsort(bad_distances)[:, :NUM_SAMPLES].flatten()\n",
    "\n",
    "good_to_label_idxs = list(set(list(closest_k_good)))\n",
    "bad_to_label_idxs = list(set(list(closest_k_bad)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24659156",
   "metadata": {},
   "source": [
    "## Annotate first samples\n",
    "\n",
    "Once we get the first samples from similarity matching, we can annotate them. \n",
    "\n",
    "Hopefully we can get examples from both classes. If that is not the case, then we should probably increase the number of samples per seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e35f2ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display\n",
    "\n",
    "def display_text(ix):\n",
    "    print('Review:')\n",
    "    display(al_dataset.iloc[ix].review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe68b4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5907ce9be97747aa95533f1210bb7ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 12 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ea6b6c5b4243da96a5b2a9a7a00268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='positive', style=ButtonStyle()), Button(description='negativ…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6feafd2277ed4c1aaabe59df9c5c4ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "import pigeonXT as pixt\n",
    "\n",
    "annotations = pixt.annotate(\n",
    "    good_to_label_idxs + bad_to_label_idxs,\n",
    "    options=['positive', 'negative'],\n",
    "    display_fn=display_text,\n",
    "    buttons_in_a_row=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ba7adc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example</th>\n",
       "      <th>changed</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19991</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14343</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4966</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30403</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17123</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3311</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>148</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29008</td>\n",
       "      <td>True</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20768</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20647</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example  changed     label\n",
       "0    19991     True  negative\n",
       "1    14343     True  positive\n",
       "2     4966     True  positive\n",
       "3    30403     True  positive\n",
       "4    17123     True  positive\n",
       "5     3311     True  positive\n",
       "6      148     True  negative\n",
       "7    29008     True  negative\n",
       "8    20768     True  positive\n",
       "9    20647     True  positive"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce4843",
   "metadata": {},
   "source": [
    "## Retrieve samples and remove them from the data pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc2b574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/hlm76d9d6r7058jg86msr16r0000gn/T/ipykernel_25173/1112712001.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_train['label'] = annotations.label.values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the best TV shows out there, if not the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I enjoyed The Night Listener very much. It's o...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great Woody Allen? No. Good Woody Allen? Defin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I admit that I almost gave up on watching TV s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Now, I flicked onto this just out of curiosity...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wow, I just saw this on T.V. as one of the \"sc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It was such a treat when this show was on beca...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I saw this at \"Dances with Films\", and it was ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               review     label\n",
       "0   One of the best TV shows out there, if not the...  positive\n",
       "1   I thought this was a wonderful way to spend ti...  positive\n",
       "2   I enjoyed The Night Listener very much. It's o...  positive\n",
       "3   A wonderful little production. <br /><br />The...  positive\n",
       "4   Great Woody Allen? No. Good Woody Allen? Defin...  positive\n",
       "5   I admit that I almost gave up on watching TV s...  positive\n",
       "6   Basically there's a family where a little boy ...  negative\n",
       "7   This show was an amazing, fresh & innovative i...  negative\n",
       "8   Now, I flicked onto this just out of curiosity...  negative\n",
       "9   Wow, I just saw this on T.V. as one of the \"sc...  negative\n",
       "10  It was such a treat when this show was on beca...  positive\n",
       "11  I saw this at \"Dances with Films\", and it was ...  positive"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = al_dataset.iloc[annotations.example.values]\n",
    "data_train['label'] = annotations.label.values\n",
    "data_train.reset_index(drop=True, inplace=True)\n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d0fd9ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "al_dataset = al_dataset.iloc[~al_dataset.index.isin(annotations.example.values)]\n",
    "al_dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443316c1",
   "metadata": {},
   "source": [
    "## Create features\n",
    "\n",
    "We should get the features from the training data and from the data pool so we can get the new samples from the trained model.\n",
    "\n",
    "We need to pay special attention to the vectorizer as the data will be changing over time.\n",
    "\n",
    "One option is to use a vectorizer that doesn't rely on a computed state like HashingVectorizer. Another option, what we are using here, is to fit another type of vectorizer at the begining on the pool dataset (which should be the largest dataset of both) and continue to use the same one throughout the process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "155a7a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df, labels=False, vectorizer=None):\n",
    "    if vectorizer:\n",
    "        features = vectorizer.transform(df.review.values)\n",
    "    else:\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        features = vectorizer.fit_transform(df.review.values)\n",
    "    \n",
    "    if labels:\n",
    "        y = df['label'].values\n",
    "        return features, y, vectorizer\n",
    "    else:\n",
    "        return features, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "017f5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_features, vectorizer = get_features(al_dataset, labels=False, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76d0b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, labels, vectorizer = get_features(data_train, labels=True, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fac5065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_features, eval_labels, vectorizer = get_features(test_dataset, labels=True, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d6f2c4",
   "metadata": {},
   "source": [
    "## Create learner\n",
    "\n",
    "Once we have the features and some data labeled, we are good to start training the initial learner.\n",
    "\n",
    "We shouldn't expect a very good performance right from the start, but this learner will help us detect the samples from the data pool that would make the most sense to label next.\n",
    "\n",
    "***\n",
    "\n",
    "There are 3 pieces of information that the learner needs:\n",
    "1) `estimator`: This is the model that will be trained. In our example, we are using scikit-learn's RandomForestClassifier\n",
    "2) `query_strategy`: This is the strategy used to sample the next data points that we should label. In our case we are going with uncertainty sampling.\n",
    "3) `X_training`: The initial training data\n",
    "\n",
    "***\n",
    "\n",
    "***Uncertainty sampling***\n",
    "\n",
    "When predicting using a ML model, we usually get a confidence score alongside the prediction. If that confidence score is far from the ideal (i.e close to the threshold of prediction), we could say that the model is uncertain about that particular prediction.\n",
    "\n",
    "In uncertainty sampling, we use such confidence score to calculate how uncertain the model is and use that to select the next samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6760f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_uncertainty(classifier, X):\n",
    "\n",
    "    # calculate uncertainty for each point provided\n",
    "    classwise_uncertainty = classifier.estimator.predict_proba(X)\n",
    "    \n",
    "    # Ignore None labels to confirm and focus on actual labels\n",
    "    prediction = classifier.predict(X)\n",
    "    prediction = np.array([1 if p != 'None' else 0 for p in list(prediction) ])\n",
    "\n",
    "    # for each point, select the maximum uncertainty\n",
    "    uncertainty = 1 - np.max(classwise_uncertainty, axis=1)\n",
    "    \n",
    "    return uncertainty * prediction#A, uncertainty * predictionB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dff911bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.13, 0.87],\n",
       "       [0.13, 0.87],\n",
       "       [0.22, 0.78],\n",
       "       [0.17, 0.83],\n",
       "       [0.14, 0.86],\n",
       "       [0.79, 0.21],\n",
       "       [0.75, 0.25],\n",
       "       [0.18, 0.82],\n",
       "       [0.13, 0.87],\n",
       "       [0.16, 0.84]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classwise_uncertainty = learner.estimator.predict_proba(new_features)\n",
    "classwise_uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ef979d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['positive', 'positive', 'positive', 'positive', 'positive',\n",
       "       'negative', 'negative', 'positive', 'positive', 'positive'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = learner.predict(new_features)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c2fe2b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.array([1 if p != 'None' else 0 for p in list(prediction) ])\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2c796467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.13, 0.22, 0.17, 0.14, 0.21, 0.25, 0.18, 0.13, 0.16])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainty = 1 - np.max(classwise_uncertainty, axis=1)\n",
    "uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b107fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13, 0.13, 0.22, 0.17, 0.14, 0.21, 0.25, 0.18, 0.13, 0.16])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncertainty = uncertainty * prediction\n",
    "uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99ca522c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 8, 4, 9, 3, 7, 5, 2, 6])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modAL.utils.selection import shuffled_argmax\n",
    "sampling = shuffled_argmax(uncertainty, n_instances=10)\n",
    "sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15c99efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertainty_sampling(classifier, X, n_instances = 10,  **uncertainty_measure_kwargs):\n",
    "    from modAL.utils.selection import shuffled_argmax\n",
    "    uncertainty  = classifier_uncertainty(classifier, X)\n",
    "    return shuffled_argmax(uncertainty, n_instances=n_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c1378780",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = ActiveLearner(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    query_strategy = uncertainty_sampling,\n",
    "    X_training=train_features, y_training=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffae604d",
   "metadata": {},
   "source": [
    "## Active learning loop\n",
    "\n",
    "Now we are ready to start the active learning loop.\n",
    "\n",
    "Since the goal of this notebook is to ilustrate the active learning process, each step of the loop will be in a different cell and they will have to be manually executed.\n",
    "\n",
    "***\n",
    "\n",
    "This loop is pretty simple:\n",
    "1) Using uncertainty sampling, retrieve the next samples to annotate\n",
    "2) Annotate samples from `1.`\n",
    "3) Re-train model and start over with step `1.`\n",
    "\n",
    "***\n",
    "\n",
    "***When should the loop be stopped?***\n",
    "\n",
    "There are different criterias one can use to consider the loop \"ended\"\n",
    "\n",
    "* *No testing data*: If we don't have any testing data, we could simply continue the loop until we see that the suggested classes for each sample are correct most of the time.\n",
    "* *Create testing data*: Another option is to take a 20% of the labeled data in each loop and keep it as eval dataset. We could use this dataset to monitor the model performance\n",
    "* *Available testing data*: If testing data is available (like in this case) we could simply continue the loop until the performance is acceptable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "083bd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-define the display function now that we can use the learner to print the suggested class\n",
    "def display_text_al(ix):\n",
    "    print('Review:')\n",
    "    display(al_dataset.iloc[ix].review)\n",
    "    print('\\n>>> Current Prediction')\n",
    "    print(learner.estimator.predict(get_features(al_dataset.iloc[[ix]], vectorizer=vectorizer)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "61b13679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Query the pool\n",
    "query_idx, query_inst = learner.query(pool_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "45bb63d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3738cb90dba043fa967b7f3b517a66cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 10 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5631d5eb914109a671698044f35768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='positive', style=ButtonStyle()), Button(description='negativ…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7560949670bf435589589f7d356dd5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Annotate samples\n",
    "annotations = pixt.annotate(\n",
    "    list(query_idx),\n",
    "    options=['positive', 'negative'],\n",
    "    display_fn=display_text_al,\n",
    "    buttons_in_a_row=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a89717ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/hlm76d9d6r7058jg86msr16r0000gn/T/ipykernel_25173/620209885.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_samples['label'] = annotations.label.values\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Add samples to dataset and re-train model\n",
    "new_samples = al_dataset.iloc[annotations.example.values]\n",
    "new_samples['label'] = annotations.label.values\n",
    "data_train = pd.concat([data_train, new_samples])\n",
    "al_dataset = al_dataset.iloc[~al_dataset.index.isin(annotations.example.values)]\n",
    "\n",
    "\n",
    "data_train.reset_index(drop=True, inplace=True)\n",
    "al_dataset.reset_index(inplace=True, drop=True)\n",
    "\n",
    "new_features, new_labels, vectorizer = get_features(new_samples, labels=True, vectorizer=vectorizer)\n",
    "pool_features, vectorizer = get_features(al_dataset, labels=False, vectorizer=vectorizer)\n",
    "\n",
    "learner.teach(new_features, new_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26f793ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.26      0.39      3893\n",
      "    positive       0.55      0.93      0.69      3863\n",
      "\n",
      "    accuracy                           0.59      7756\n",
      "   macro avg       0.67      0.59      0.54      7756\n",
      "weighted avg       0.67      0.59      0.54      7756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (Optional) Step 4: Test model in eval data.\n",
    "# This step doesn't need to be done in each iteration.\n",
    "y_hat = learner.estimator.predict(eval_features)\n",
    "print(classification_report(eval_labels, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2659c5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotated percentage: 0.23%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Annotated percentage: {round((data_train.shape[0]/train_dataset.shape[0])*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac9ad03",
   "metadata": {},
   "source": [
    "## Test with full annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a7c1a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.rename(columns={'sentiment':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2bb017ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_features, full_train_labels, vectorizer = get_features(train_dataset, labels=True, vectorizer=vectorizer)\n",
    "full_test_features, full_test_labels, vectorizer = get_features(test_dataset, labels=True, vectorizer=vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "559b3695",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0f37db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(full_train_features, full_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4052a25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.86      0.86      3893\n",
      "    positive       0.86      0.85      0.85      3863\n",
      "\n",
      "    accuracy                           0.85      7756\n",
      "   macro avg       0.85      0.85      0.85      7756\n",
      "weighted avg       0.85      0.85      0.85      7756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_hat = clf.predict(full_test_features)\n",
    "print(classification_report(full_test_labels, y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alstreamlit",
   "language": "python",
   "name": "alstreamlit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
